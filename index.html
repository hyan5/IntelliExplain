<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="IntelliExplain">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon-hy.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://murongyue.github.io/MathVC.github.io/">
            MathVC
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2310.03094">
            LLM Cascading
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2308.04030">
            Gentopia
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2310.03249">
            LLM as Planners
          </a>
          <a class="navbar-item" href="https://arxiv.org/pdf/2305.13469">
            MailEx
          </a>
          <a class="navbar-item" href="https://aclanthology.org/2023.acl-long.177.pdf">
            NL Feedback Simulation for Code
          </a>
          <!-- <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hyan5.github.io/">Hao Yan</a>,</span>
            <span class="author-block">
              <a href="https://cs.gmu.edu/~tlatoza/">Thomas D. LaToza</a>,</span>
            <span class="author-block">
              <a href="https://ziyuyao.org/">Ziyu Yao</a></span>
            <!-- <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">{hyan5, tlatoza, ziyuyao}@gmu.edu</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Department of Computer Science, George Mason University</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2405.10250"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hyan5/IntelliExplain-Interactive-Code-Generation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <p style="font-weight: bold; font-size: 20px;">
        IntelliExplain is an LLM-powered system aiding non-professional programmers for interactive code generation. IntelliExplain enables non-professional programmers to write code in natural language without requiring direct interaction with source code. The user starts with a question in natural language (NL), accompanied by relevant context (top). IntelliExplain then generates source code and confirms its understanding of the question by presenting an NL explanation to the user. When this understanding is incorrect, the user can provide corrective feedback in NL and instruct the system for error correction.
      </p>
      <h3 class="title is-4">Text-to-SQL Demo</h3>
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/demo_sql.mp4"
                type="video/mp4">
      </video>
      <h3 class="title is-4">Python Code Generation Demo</h3>
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/demo_py.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-justified">
                    <md-block rendered="content"><p><em>Updates</em></p>
                        <ul>
                            <!--<li>2024-04-05: <a href="https://huggingface.co/spaces/salokr/PRomPTed">&#129303; demo</a> is online. Get your api-keys ready and check it out.</li>-->
                            <li>2024-05: The code is coming soon!</li>
                            <li>2024-05: <a href="https://arxiv.org/pdf/2405.10250">ArXiv</a> version is available. Please check out our preprint.
                            </li>
                        </ul>
                    </md-block>
                  </div>
              </div>
          </div>
    </div>
</section>

<hr>  <!--style="width: 80%; margin: auto;" -->

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Motivation</h2>
    <p>
      Non-professional programmers are individuals who have basic knowledge of computation (e.g. mathematical operation, linear algebra, etc.) but much less than a computer science major or professional engineer. Their limited introductory programming experience making them hard to write and debug source code themselves.
    </p>
    <br>
    <p>
      LLMs have demonstrated potential in translating natural language instructions into code. Users can interact with LLMs (e.g., ChatGPT) by posing programming questions and optionally providing input-output samples to specify requirements. When errors are identified or the generated code fails to meet the specified criteria, users often follow up with feedback prompting LLMs to refine the code solution. Despite its simplicity, the difficulty in accurately pinpointing and articulating errors in the generated code makes it challenging for non-professional users to provide meaningful corrective feedback (Figure 1 Right).
    </p>
    <br>
    <figure>
      <center>
      <img src="./static/images/overview.png"/>
      <figurecaption>Figure 1: Comparsion between using IntelliExplain and vanilla GPT-3.5 for interactive code generation.</figurecaption>
    </figure>
    <br>
    <p>
      In this work, we present IntelliExplain, which offers a novel human-LLM interaction paradigm to enhance non-professional programmers' experience by enabling them to <strong><em>interact with source code via natural language explanations (Figure 1 Left)</em></strong>. Users interact with IntelliExplain by <strong><em>providing natural language corrective feedback</em></strong> on errors they identify from the explanations. Feedback is used by the system to revise the code, until the user is satisfied with explanations by the system of the code.
    </p>
    <br>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Natural Language Explanation</h2>
        <p>
          The most straightforward way is to ask the LLM to explain their predicted code. However, this vanilla approach often results in explanations that are lengthy and too technical to be read by non-professional programmers. To address this limitation, we propose two distinct styles for program explanations: Question Restatement for text-to-SQL and Concise Description for Python Code Generation.
        </p>
        <br>

        <h3 class="title is-4">Question Restatement (for Text-to-SQL)</h3>
        <div class="content has-text-justified">
          <p>
            In our preliminary experiments, we observed that a significant portion of LLM errors in text-to-SQL stemmed from a misunderstanding of concepts within the original question. However, such mistakes can hardly be captured from a vanilla explanation of the SQL code, which is often full of technical jargon distracting users from identifying concepts involved in the code. Observing this challenge, we instead propose to use "restated question" from the source code as an explanation for text-to-SQL programming. A restated question is an NL question generated by the LLM to describe the intent of a model-generated code.
          </p>
          <figure>
            <center>
            <img src="./static/images/qr_sql.png"/>
            <br>
            <figurecaption>Table 1: Question Restatement for text-to-SQL</figurecaption>
          </figure>
        </div>
      
        <h3 class="title is-4">Concise Description (for Python Code Generation)</h3>
        <div class="content has-text-justified">
          <p>
            In our exploration, we observed that question restatement proves to be more effective for short code snippets, like SQL queries, and can effectively address conceptual misunderstanding errors. However, it cannot capture the inner logical errors in scenarios involving lengthy generated code and intricate coding tasks, especially when the LLM makes an inaccurate generation despite correctly understanding the input question. This raises a need for a more fine-grained exploration of the inner logic. We achieve this by proposing a concise explanation of the source code, striking a balance between the succinct question restatement and the technical and lengthy line-by-line explanation.
          </p>
          <figure>
            <center>
            <img src="./static/images/cd_py.png"/>
            <br>
            <figurecaption>Table 2: Consice Description for Python Code Generation</figurecaption>
          </figure>
        </div>
        <h2 class="title is-3">Interaction Paradigm</h2>
        <div class="content has-text-justified">
          <p>
            To utilize our designed explanation for assisting non-expert programmers in coding tasks, we introduce an interaction paradigm. Our designed interaction paradigm consists of (1) user asking a coding question and providing the necessary context that are necessary for answering the question; (2) LLM predicting an initial code answer; (3) LLM generating an NL explanation for the initial code; (4) user judging the explanation and determining whether the code is correct; if any error is found in the explanation, user providing NL feedback for error correction; and (5) the LLM refining its answer based on user feedback. Steps 3-5 repeat until users cannot find more errors in the explanation.
          </p>
        </div>
        <div class="is-centered">
          <figure>
            <center>
            <img src="./static/images/inter_para.png" width="600"/>
            <br>
            <figurecaption>Figure 2: Interaction paradigm of IntelliExplain</figurecaption>
          </figure>
        </div> 
        <br/>

      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">User Study and Results</h2>
        <p>
          We evaluate IntelliExplain by conducting a user study involving 20 participants (IRB approved). We use GPT-3.5 (turbo-0613) as backend LLM. Our user study demonstrates that users with IntelliExplain achieve a significantly higher success rate <strong><i>11.6%</i></strong> and <strong><i>25.3%</i></strong> better than with vanilla GPT-3.5, while also requiring <strong><i>39.0%</i></strong> and <strong><i>15.6%</i></strong> less time in Text-to-SQL and Python code generation tasks, respectively.
        </p>

        <br>
        <h3 class="title is-4">Overall Performance</h3>
        <div class="content has-text-justified">
          <p>
            IntelliExplain enables users to achieve success rates 11.6% and 25.3%  higher than the vanilla GPT-3.5 group in text-to-SQL and Python code generation, respectively. The t-Test showed that the means between the two groups are statistically significant in success rate (SQL: <em>t=1.935, p=0.043</em>; Python: <em>t=2.361, p=0.021</em>) and time spent on each question for text-to-SQL (SQL: <em>t=-2.611, p=0.014</em>), but no difference in time spent per question for Python code generation (Python: <em>t=-1.374, p=0.101</em>).
          </p>
          <figure>
            <center>
            <img src="./static/images/overall_performance.png" width="500"/>
            <br>
            <figurecaption>Table 3: Overall performance using IntelliExplain compared to vanilla GPT-3.5</figurecaption>
          </figure>
        </div>
        <h3 class="title is-4">Designed NL Explanation Can Accurately Describe the Source Code</h3>
        <div class="content has-text-justified">
          <p>
            Our explanations generally align precisely with the generated code. In addition, over <em>50%</em> of text-to-SQL and <em>70%</em> of Python code generation erros in the soucre code can be found via our designed explaination as shown in Table 4. We delve into cases that errors cannot be easily identified in the explaination and find that this limitation arises from the challenge of encapsulating intricate inner logic into concise explanations. It highlights the challenge of striking a balance between presenting concise and easy-to-understand NL explanations and presenting more fine-grained inner logic of the code.
          </p>
        </div>
        <div class="columns">
          <div class="column has-text-centered">
            <img src="./static/images/tab_4_b.png" width="600"/>
            <p>(a) Text-to-SQL</p>
          </div>
          <div class="column has-text-centered">
            <img src="./static/images/tab_4_a.png" width="400"/>
            <p>(b) Python Code Generation</p>
          </div>
        </div>
        <div class="has-text-centered">
          <p>Table 4: Our designed explaintion can caputure <span style="color: red;">errors</span> in the source code.</p>
        </div>
        <br/>

        <h3 class="title is-4">Users Can Provide Effective Feedback based on the NL Explanation</h3>
        <div class="content has-text-justified">
          <p>
            Throughout the user study, we observed a variety of feedback from participants using IntelliExplain which can be broadly classified into three categories:
          </p>
          <ul>
            <li>
              <strong>Instructions for Error Correction</strong>: Users can spot errors in the explanation and suggest how to fix them. This implies the effectiveness of our explanations in aiding non-professional programmers in code understanding and debugging.
            </li>
            <li>
              <strong>Question Rephrasing</strong>: This type of feedback suggests that users perceive errors in the explanation, attributing them to the underspecified intent of the original question.
            </li>
            <li>
              <strong>Step-by-Step Instruction</strong>: Users offer detailed step-by-step instructions to guide the model in solving the problem based on their understanding.
            </li>
        </ul>
        </div>
        <figure class="has-text-justified">
          <img src="./static/images/feedback_type.png"/>
          <figurecaption>Table 5: Types and frequencies (for SQL/Python programming) of feedback provided by users. Errors mentioned in the explanation are marked in <span style="color: red;">red</span>. Diverse types of feedback received from user study demonstrated the effectiveness of our explanation in aiding non-professional programmers in both code comprehension and debugging.</figurecaption>
        </figure>
        <br/>

        <h3 class="title is-4">IntelliExplain Has Ability to Make Corrections Based on User Feedback</h3>
        <div class="content has-text-justified">
          <p>
            In Table 6, the success rates of different feedback types illustrate IntelliExplain's ability in integrating human feedback for error correction. 
          </p>
          <figure>
            <center>
            <img src="./static/images/feedback_sr.png" width="500"/>
            <br>
            <figurecaption>Table 6: Success rate of IntelliExplain for each feedback type. The percentages are calculated by dividing the number of successful error corrections for each feedback type by the number of total feedback of the same type per conversation.</figurecaption>
          </figure>
          <p>
            Despite the achievement in incorporating human feedback in IntelliExplain, we observed a notable gap in the success rate from the user study especially in text-to-SQL. A closer examination of failed cases revealed various contributing factors:
            <ul>
              <li>
                User feedback was sometimes too vague or abstract and lacked the specificity needed for precise
                corrections.
              </li>
              <li>
                Misaligned reasoning between participants’ mental models and the LLM's thought led to human feedback based on flawed assumptions.
              </li>
              <li>
                Although explanations can capture small changes in the source code after previous rounds of error correction, users sometimes fail to recognize these changes, resulting in mistakes when providing feedback.
              </li>
            </ul>
          </p>
        </div>
        <h3 class="title is-4">Performance of IntelliExplain with GPT-4 as Backbone LLM</h3>
        <div class="content has-text-justified">
          <p>
            We conducted a pilot study to determine if our designed explanation and interaction paradigm remain effective with a more powerful LLM model. Our findings indicate that all proposed mechanisms remain operational, demonstrating comparable success rates. Further analysis into the quality of explanations generated by different LLMs revealed that GPT-4 generates an explanatory sentence on how to solve the problem in general (in <span style="color: green;">green</span>). This information makes the explanation generated by GPT-4 more comprehensible than GPT-3.5.
          </p>
          <figure>
            <center>
            <img src="./static/images/gpt-4.png"/>
            <br>
            <figurecaption>
              Table 7: Explanations provided by GPT-3.5 and GPT-4 on the same question for the generated code.
            </figurecaption>
          </figure>
        </div>
      </div>
    </div>


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Case Study</h2>
        <div class="content has-text-justified">
          <p>
            We showed one real conversation using IntelliExplain in Figure 3. With IntelliExplain, users can comprehend the source code via NL explanation to more easily identify potential errors. IntelliExplain makes corrections based on user feedback. In contrast, when interacting directly with code in vanilla GPT-3.5, non-professional programmers may struggle to understand source code and fail to identify errors. Vanilla GPT-3.5 may also sometimes generates responses that are irrelevant to the user question (Figure 3 Right in <span style="color: red">red background color</span>).
          </p>
          <figure>
            <center>
            <img src="./static/images/case_study.png"/>
            <br>
            <figurecaption>
              Figure 3: Case study from Python Code Generation using IntelliExplain and vanilla GPT-3.5.
            </figurecaption>
          </figure>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3">Acknowledgments</h2>
        <p>
          This project was sponsored by NSF SHF 2311468, GMU College of Computing and Engineering, and GMU Department of Computer Science. We appreciate the Office of Research Integrity and Assurance at GMU for their work in reviewing and approving our Institutional Review Board (IRB) application. We also appreciate comments from students in GMU NLP and SE labs.
        </p>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yan2024intelliexplain,
      title={IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers}, 
      author={Hao Yan and Thomas D. Latoza and Ziyu Yao},
      year={2024},
      eprint={2405.10250},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
